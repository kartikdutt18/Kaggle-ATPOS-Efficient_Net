{"cells":[{"metadata":{},"cell_type":"markdown","source":"# **Directory**"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"for dirname, _, filenames in os.walk('/kaggle/input/aptos2019-blindness-detection/'):\n    print(dirname)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Visualizing Training Data**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Load Datasets\nBASE_PATH='/kaggle/input/aptos2019-blindness-detection/'\ntrain_dataset=pd.read_csv(os.path.join(BASE_PATH,'train.csv'))\ntest_dataset=pd.read_csv(os.path.join(BASE_PATH,'test.csv'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataset.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_dataset.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Plot Images\nfrom PIL import Image\nfrom matplotlib.pyplot import imshow\nimport matplotlib.pyplot as plt\nfig=plt.figure(figsize=(32, 32)) #Size of Figure\ncolumns = 3 #Columns in fig\nrows = 5 #Rows in Fig\n#Total images = row* columns\nfor i in range(1,rows*columns+1):\n    IMG_PATH=BASE_PATH+'train_images/'\n    img=Image.open(os.path.join(IMG_PATH,train_dataset.iloc[i][0]+'.png'))\n    fig.add_subplot(rows, columns, i)\n    plt.imshow(img)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## ****Importing and Installing Libraries****"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Installing Libraries\n!pip install efficientnet-pytorch\n!pip install torchsummary\nfrom torchsummary import summary","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import PIL\nimport sys\nimport torch\nfrom time import time\nimport torchvision\nfrom PIL import Image\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils import data\nfrom torch.autograd import Variable\nimport torchvision.transforms as transforms\nfrom efficientnet_pytorch import EfficientNet","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **Data-Loader**"},{"metadata":{"trusted":true},"cell_type":"code","source":"class Dataset(data.Dataset):\n    def __init__(self,csv_path,images_path,transform=None):\n        self.train_set=pd.read_csv(csv_path) #Read The CSV and create the dataframe\n        self.train_path=images_path #Images Path\n        self.transform=transform # Augmentation Transforms\n    def __len__(self):\n        return len(self.train_set)\n    \n    def __getitem__(self,idx):\n        file_name=self.train_set.iloc[idx][0]+'.png' \n        label=self.train_set.iloc[idx][1]\n        img=Image.open(os.path.join(self.train_path,file_name)) #Loading Image\n        if self.transform is not None:\n            img=self.transform(img)\n        return img,label","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **Defining Transforms and Parameters for Training**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Network Params\nparams = {'batch_size': 16,\n          'shuffle': True\n         }\nepochs = 100\nlearning_rate=1e-3","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"transform_train = transforms.Compose([transforms.Resize((224,224)),transforms.RandomApply([\n        torchvision.transforms.RandomRotation(10),\n        transforms.RandomHorizontalFlip()],0.7),\n\t\ttransforms.ToTensor()])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"training_set=Dataset(os.path.join(BASE_PATH,'train.csv'),os.path.join(BASE_PATH,'train_images/'),transform=transform_train)\ntraining_generator=data.DataLoader(training_set,**params)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"use_cuda = torch.cuda.is_available()\ndevice = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\nprint(device)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **Importing the Model (Efficient Net)**"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = EfficientNet.from_pretrained('efficientnet-b0', num_classes=3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.to(device)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(summary(model, input_size=(3, 512, 512)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"PATH_SAVE='./Weights/'\nif(not os.path.exists(PATH_SAVE)):\n    os.mkdir(PATH_SAVE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\nlr_decay=0.99\noptimizer = optim.Adam(model.parameters(), lr=learning_rate)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Training The Model**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Eye to create an 5x5 tensor\neye = torch.eye(5).to(device)\nclasses=[0,1,2,3,4]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history_accuracy=[]\nhistory_loss=[]\nepochs = 50","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for epoch in range(epochs):  \n    running_loss = 0.0\n    correct=0\n    total=0\n    class_correct = list(0. for _ in classes)\n    class_total = list(0. for _ in classes)\n    for i, data in enumerate(training_generator, 0):\n        inputs, labels = data\n        t0 = time()\n        inputs, labels = inputs.to(device), labels.to(device)\n        labels = eye[labels]\n        optimizer.zero_grad()\n        outputs = model(inputs)\n        loss = criterion(outputs, torch.max(labels, 1)[1])\n        _, predicted = torch.max(outputs, 1)\n        _, labels = torch.max(labels, 1)\n        c = (predicted == labels.data).squeeze()\n        correct += (predicted == labels).sum().item()\n        total += labels.size(0)\n        accuracy = float(correct) / float(total)\n        \n        history_accuracy.append(accuracy)\n        history_loss.append(loss)\n        \n        loss.backward()\n        optimizer.step()\n        \n        for j in range(labels.size(0)):\n            label = labels[j]\n            class_correct[label] += c[j].item()\n            class_total[label] += 1\n        \n        running_loss += loss.item()\n        \n        print( \"Epoch : \",epoch+1,\" Batch : \", i+1,\" Loss :  \",running_loss/(i+1),\" Accuracy : \",accuracy,\"Time \",round(time()-t0, 2),\"s\" )\n    for k in range(len(classes)):\n        if(class_total[k]!=0):\n            print('Accuracy of %5s : %2d %%' % (classes[k], 100 * class_correct[k] / class_total[k]))\n        \n    print('[%d epoch] Accuracy of the network on the Training images: %d %%' % (epoch+1, 100 * correct / total))\n        \n    if epoch%10==0 or epoch==0:\n        torch.save(model.state_dict(), os.path.join(PATH_SAVE,str(epoch+1)+'_'+str(accuracy)+'.pth'))\n        \ntorch.save(model.state_dict(), os.path.join(PATH_SAVE,'Last_epoch'+str(accuracy)+'.pth'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **Visualizing The Training Accuracy and losses**"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(history_accuracy)\nplt.plot(history_loss)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Inference**"},{"metadata":{"trusted":true},"cell_type":"code","source":"model.load_state_dict(torch.load('/kaggle/input/efficient-net/Weights/21_0.9243582741671218.pth'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.eval()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_transforms = transforms.Compose([transforms.Resize(512),\n                                      transforms.ToTensor(),\n                                     ])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def predict_image(image):\n    image_tensor = test_transforms(image)\n    image_tensor = image_tensor.unsqueeze_(0)\n    input = Variable(image_tensor)\n    input = input.to(device)\n    output = model(input)\n    index = output.data.cpu().numpy().argmax()\n    return index","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission=pd.read_csv(BASE_PATH+'sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_csv=pd.DataFrame(columns=['id_code','diagnosis'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"IMG_TEST_PATH=os.path.join(BASE_PATH,'test_images/')\nfor i in range(len(submission)):\n    img=Image.open(IMG_TEST_PATH+submission.iloc[i][0]+'.png')\n    prediction=predict_image(img)\n    submission_csv=submission_csv.append({'id_code': submission.iloc[i][0],'diagnosis': prediction},ignore_index=True)\n    if(i%10==0 or i==len(submission)-1):\n        print('[',32*'=','>] ',round((i+1)*100/len(submission),2),' % Complete')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_csv.to_csv('submission.csv',index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}